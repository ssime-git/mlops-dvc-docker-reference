# Message aux Ã‰tudiants - Phase 2: Architecture DVC + Docker

Bonjour Ã  tous,

Pour la Phase 2, vous allez dÃ©composer votre pipeline ML en microservices containerisÃ©s, orchestrÃ©s par DVC.

## ğŸ“¦ Repository de RÃ©fÃ©rence

J'ai crÃ©Ã© un exemple complet qui montre le pattern Ã  suivre:

**[mlops-dvc-docker-reference](lien-vers-repo)**

âš ï¸ **Important:** Ce n'est PAS du code Ã  copier-coller. C'est une **implÃ©mentation de rÃ©fÃ©rence** pour comprendre l'architecture.

## ğŸ¯ Ce que vous devez comprendre

### 1. Architecture GÃ©nÃ©rale

```
DVC Orchestrator (conteneur)
    â†“ via Docker socket
Microservices: [Ingest] â†’ [Preprocess] â†’ [Train] â†’ [Evaluate]
```

**Questions clÃ©s:**
- Pourquoi DVC tourne dans un conteneur ?
- Comment un conteneur peut-il lancer d'autres conteneurs ?
- Qu'est-ce que `/var/run/docker.sock` et pourquoi le monter ?

### 2. Pattern Docker Socket

Le conteneur DVC doit pouvoir spawner vos microservices (autres conteneurs).

**Ã€ rechercher:**
- Docker socket sharing vs Docker-in-Docker
- Sibling containers pattern
- SÃ©curitÃ© et implications

ğŸ“– Voir `docs/DOCKER_SOCKET.md` dans le repo de rÃ©fÃ©rence.

### 3. DVC + DagsHub Integration

**Ce que DagsHub vous offre:**
- **DVC Remote**: Storage S3-compatible (100GB gratuit)
- **MLflow Server**: Tracking des expÃ©riences
- **Model Registry**: Versioning des modÃ¨les

**Ã€ comprendre:**
- Comment configurer le remote DVC avec DagsHub
- Pourquoi ne PAS sauvegarder les modÃ¨les localement
- Integration MLflow â†’ Model Registry automatique

ğŸ“– Voir `docs/DAGSHUB_SETUP.md` dans le repo de rÃ©fÃ©rence.

## ğŸ” Concepts Ã  MaÃ®triser

1. **DVC Pipeline**
   - DÃ©finition des stages dans `dvc.yaml`
   - Dependencies (`deps`), outputs (`outs`), metrics
   - Comment DVC dÃ©tecte les changements

2. **Containerisation par Stage**
   - Un Dockerfile par microservice
   - Partage de volumes entre conteneurs
   - Variables d'environnement pour configuration

3. **Orchestration**
   - DVC comme orchestrateur simple (Phase 2)
   - PrÃ©paration pour Airflow (Phase 3)

## ğŸ“‹ Livrables Phase 2

Pour votre projet, vous devez crÃ©er:

1. **Architecture Microservices**
   - [ ] Un conteneur par stage (minimum 3 stages)
   - [ ] `dvc.yaml` dÃ©finissant le pipeline
   - [ ] Volumes partagÃ©s pour data/models

2. **DagsHub Integration**
   - [ ] DVC remote configurÃ©
   - [ ] MLflow tracking actif
   - [ ] ModÃ¨les dans le registry (pas en local!)

3. **Orchestration ContainerisÃ©e**
   - [ ] DVC runner en conteneur
   - [ ] Docker socket correctement montÃ©
   - [ ] `docker-compose.yml` pour dev local

4. **Documentation**
   - [ ] README expliquant l'architecture
   - [ ] Instructions de setup
   - [ ] Choix techniques justifiÃ©s

## ğŸ’¡ Conseils

**Ne PAS faire:**
- âŒ Copier-coller sans comprendre
- âŒ MÃ©langer code host et code container
- âŒ Sauvegarder les modÃ¨les en local avec DVC

**Ã€ faire:**
- âœ… Comprendre le pattern Docker socket
- âœ… Tester chaque stage individuellement
- âœ… VÃ©rifier l'intÃ©gration DagsHub
- âœ… Documenter vos choix

## ğŸš€ Pour DÃ©marrer

1. **Clonez le repo de rÃ©fÃ©rence** et Ã©tudiez la structure
2. **Lisez les docs** (`DOCKER_SOCKET.md`, `DAGSHUB_SETUP.md`)
3. **Testez localement** le pipeline de rÃ©fÃ©rence
4. **Adaptez Ã  votre projet** (pas de copier-coller!)

## â“ Questions de Recherche

Avant de commencer, assurez-vous de pouvoir rÃ©pondre Ã :

1. Quelle est la diffÃ©rence entre Docker-in-Docker et socket sharing?
2. Comment DVC sait-il quand re-exÃ©cuter un stage?
3. Pourquoi utiliser le Model Registry plutÃ´t que DVC pour les modÃ¨les?
4. Comment les conteneurs siblings partagent-ils des donnÃ©es?
5. Quel est l'avantage de containeriser DVC lui-mÃªme?

## ğŸ“… Timeline

- **30 janv - 2 fÃ©v**: Setup architecture + DagsHub
- **3-4 fÃ©v**: Microservices + tests individuels
- **5-6 fÃ©v**: Orchestration complÃ¨te + validation

## ğŸ†˜ Support

Si vous bloquez:
1. **D'abord**: Recherchez le concept (Docker socket, DVC pipeline, etc.)
2. **Ensuite**: Consultez le repo de rÃ©fÃ©rence
3. **En dernier**: Posez des questions spÃ©cifiques (pas "Ã§a marche pas")

**Bon courage!** La Phase 2 est challenging mais elle vous prÃ©pare parfaitement pour Airflow en Phase 3.

L'objectif n'est pas juste de faire fonctionner un pipeline, mais de **comprendre l'architecture** qui vous servira en production.

â€” SÃ©bastien
